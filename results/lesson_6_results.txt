************************************************
*  Welcome to the sixth lesson of the RL-Lab!  *
*    (Tensorflow-PyTorch and Neural Networks)    *
**************************************************

A) The global minimum of the function: '2x^2 + 2xy + 2y^2 - 6x' using Keras is:
        <x:2.0, y:-1.0> with value -6.0

A) The global minimum of the function: '2x^2 + 2xy + 2y^2 - 6x' using PyTorch is:
        <x:2.0, y:-1.0> with value -6.0


B) Showing the deep neural networks structure:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 8)                 16        
                                                                 
 dense_1 (Dense)             (None, 8)                 72        
                                                                 
 dense_2 (Dense)             (None, 8)                 72        
                                                                 
 dense_3 (Dense)             (None, 1)                 9         
                                                                 
=================================================================
Total params: 169 (676.00 Byte)
Trainable params: 169 (676.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
TorchModel(
  (fc1): Linear(in_features=1, out_features=8, bias=True)
  (fc2): Linear(in_features=8, out_features=8, bias=True)
  (fc3): Linear(in_features=8, out_features=8, bias=True)
  (output): Linear(in_features=8, out_features=1, bias=True)
)

Pre-conversion forward propagation of the value -1.4
Keras output:  0.2163
PyTorch output:  0.2495
Post-conversion forward propagation of the value -1.4
Keras output:  0.2163
PyTorch output:  0.2163

C) Collect a dataset from the interaction with the environment

D) Training a DNN to predict the reward of a state:
Pre Training Reward Prediction Keras-PyTorch model: 
        state 0 => reward: 0.0 
        state 48 => reward: 13.044615745544434 

Post Training Keras Reward Prediction:
        state 0 => reward: -0.09993496537208557 
        state 48 => reward: -0.10066357254981995 
Post Training PyTorch Reward Prediction:
        state 0 => reward: -0.09993235766887665 
        state 48 => reward: -0.10065899789333344 
